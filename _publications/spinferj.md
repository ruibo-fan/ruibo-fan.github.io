---
title: "Exploiting Low-Level Sparsity for Efficient Large Language Model Inference on GPUs with SpInfer"
collection: publications
venue: "ACM Transactions on Computer Systems (TOCS)"
date: 2025-10-01

citation: "**Ruibo Fan**, et al., \"Exploiting Low-Level Sparsity for Efficient Large Language Model Inference on GPUs with SpInfer,\" *ACM Transactions on Computer Systems (TOCS)*, invited, under review."

paperurl: "https://your-spinfer-tocs-paper-url"
codeurl:  "https://your-spinfer-tocs-code-url"
bibtexurl: "https://your-spinfer-tocs-bibtex-url"
type: "journals"
category: journals
---

This **journal extension** of SpInfer provides a more comprehensive study of exploiting **low-level sparsity** for efficient LLM inference on GPUs. It includes extended methodology, deeper analysis, and additional experiments compared to the conference version, further validating the effectiveness and generality of SpInfer.
