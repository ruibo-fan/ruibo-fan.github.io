---
permalink: /
title: "About Me"
excerpt: "About me"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

[cite_start]I am a 3rd-year Ph.D. candidate at the [Hong Kong University of Science and Technology (Guangzhou)](https://www.hkust-gz.edu.cn/), advised by Prof. [Xiaowen Chu](https://xiaowen-chu.github.io/) (Primary Advisor) and Prof. [Wei Wang](https://cse.hkust.edu.hk/~weiwa/) (Co-Advisor, HKUST CSE Department)[cite: 1, 6, 8, 31].

My research interests lie in **High-Performance Computing**, particularly focused on **GPU architecture and optimization**. [cite_start]I am currently investigating methods to accelerate sparse matrix operations and graph neural networks on modern GPU architectures[cite: 8, 26, 28, 33].

[cite_start]Prior to joining HKUST(GZ), I received my Master's degree from **Peking University** (2019-2022) at the Academy for Advanced Interdisciplinary Studies, and my Bachelor's degree from **Huazhong University of Science and Technology** (2015-2019) in the School of Artificial Intelligence and Automation[cite: 9, 10, 11, 23, 25].

I am passionate about bridging the gap between theoretical computer architecture and practical performance optimization for real-world applications. My goal is to develop efficient algorithms and systems that can fully utilize modern hardware capabilities to accelerate computational workloads across various domains including AI, scientific computing, and large-scale data processing.

## Research Interests
* GPU Architecture & Parallel Computing
* Sparse Matrix Operations
* Large Language Model Inference
* Graph Neural Networks

---

## News & Updates

* [cite_start]**February 2025:** üèÜ SpInfer has passed the artifact evaluation and received 3 badges (Available, Functional, Reproducible) at **EuroSys 2025**! [cite: 29]
* **January 2025:** Our paper *"SpInfer: Leveraging Low-Level Sparsity for Efficient Large Language Model Inference on GPUs"* has been accepted by **EuroSys 2025** (CCF-A). Congratulations to all co-authors! (30 papers were accepted out of 367 new submissions) [cite_start][cite: 28, 29]
* [cite_start]**January 2025:** Our collaborative work *"StbLLM: Breaking the 1-bit barrier with structured binary LLMs"* has been accepted to **ICLR 2025**! [cite: 39]
* [cite_start]**January 2025:** Our preprint *"Dissecting the NVIDIA Hopper Architecture through Microbenchmarking and Multiple Level Analysis"* is now available on arXiv. [cite: 37, 42]
